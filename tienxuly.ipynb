{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba49dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\harry\\desktop\\huy o\\cool\\du bao thoi tiet\\.venv\\lib\\site-packages (2.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\harry\\desktop\\huy o\\cool\\du bao thoi tiet\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\harry\\desktop\\huy o\\cool\\du bao thoi tiet\\.venv\\lib\\site-packages (from pandas) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harry\\desktop\\huy o\\cool\\du bao thoi tiet\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harry\\desktop\\huy o\\cool\\du bao thoi tiet\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\harry\\desktop\\huy o\\cool\\du bao thoi tiet\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harry\\desktop\\huy o\\cool\\du bao thoi tiet\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016e6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a6dae9e",
   "metadata": {},
   "source": [
    "mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51204cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cities = [\n",
    "    \"Bac Lieu\", \"Ho Chi Minh City\", \"Tam Ky\", \"Ben Tre\", \"Hoa Binh\", \"Tan An\", \n",
    "    \"Bien Hoa\", \"Hong Gai\", \"Thai Nguyen\", \"Buon Me Thuot\", \"Buon Ma Thuot\", \"Hue\", \"Thanh Hoa\", \n",
    "    \"Ca Mau\", \"Long Xuyen\", \"Tra Vinh\", \"Cam Pha\", \"My Tho\", \"Tuy Hoa\", \n",
    "    \"Cam Ranh\", \"Nam Dinh\", \"Uong Bi\", \"Can Tho\", \"Nha Trang\", \"Viet Tri\", \n",
    "    \"Chau Doc\", \"Phan Rang\", \"Vinh\", \"Da Lat\", \"Phan Thiet\", \"Vinh Long\", \n",
    "    \"Ha Noi\", \"Play Cu\", \"Pleiku\", \"Vung Tau\", \"Hai Duong\", \"Qui Nhon\", \"Yen Bai\", \n",
    "    \"Hai Phong\", \"Rach Gia\", \"Hanoi\", \"Soc Trang\"\n",
    "]\n",
    "\n",
    "top_cities = [ \n",
    "    \"Hanoi\", \"Ha Noi\", \"Hai Phong\", \"Vinh\", \"Hue\", \"Nha Trang\",\n",
    "    \"Da Lat\", \"Buon Ma Thuot\", \"Ho Chi Minh City\", \"Can Tho\", \"Ca Mau\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5abee800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reduced from 45490 to 45490 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "top_cities = [ \n",
    "    \"Hanoi\", \"Ha Noi\", \"Hai Phong\", \"Vinh\", \"Hue\", \"Nha Trang\",\n",
    "    \"Da Lat\", \"Buon Me Thuot\", \"Buon Ma Thuot\", \"Ho Chi Minh City\", \"Can Tho\", \"Ca Mau\"\n",
    "]\n",
    "\n",
    "# 1. Read the file\n",
    "df2 = pd.read_csv(\"vietnam_weather_kaggle.csv\")\n",
    "\n",
    "# 2. Filter: Keep rows where 'city' IS IN the list\n",
    "# This keeps \"Ha Noi\" OR \"Hanoi\" OR \"Hue\", etc.\n",
    "df_filtered = df2[df2['province'].isin(top_cities)]\n",
    "\n",
    "# 3. Save\n",
    "df_filtered.to_csv(\"vietnam_weather_kaggle.csv\", index=False)\n",
    "print(f\"✅ Reduced from {len(df2)} to {len(df_filtered)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0823ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged! Total rows: 45520\n",
      "         time  temperature_2m_max  temperature_2m_min  temperature_2m_mean  \\\n",
      "0  2009-01-01                17.3                13.4                 15.1   \n",
      "1  2009-01-02                17.6                12.2                 14.8   \n",
      "2  2009-01-03                18.3                10.8                 14.4   \n",
      "3  2009-01-04                20.6                12.4                 16.2   \n",
      "4  2009-01-05                22.6                14.1                 17.6   \n",
      "\n",
      "   precipitation_sum rain_sum wind_speed_10m_max   city official_name  \n",
      "0                0.0      0.0               11.2  Hanoi         Hanoi  \n",
      "1                0.0      0.0                9.7  Hanoi         Hanoi  \n",
      "2                0.0      0.0                8.1  Hanoi         Hanoi  \n",
      "3                0.0      0.0               10.5  Hanoi         Hanoi  \n",
      "4                0.1      0.1               11.1  Hanoi         Hanoi  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the two files\n",
    "# We use 'index_col=None' to ensure we read everything raw\n",
    "df1 = pd.read_csv(\"vietnam_weather_daily.csv\")       # Your first file\n",
    "df2 = pd.read_csv(\"vietnam_weather_daily2.csv\")       # The new file you just grabbed\n",
    "\n",
    "# 2. Check for \"duplicate index columns\"\n",
    "# Your snippet shows file 1 has a \"0, 1, 2\" column at the start. \n",
    "# Sometimes this gets named \"Unnamed: 0\". We should remove it if it exists.\n",
    "if 'Unnamed: 0' in df1.columns:\n",
    "    df1 = df1.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "if 'Unnamed: 0' in df2.columns:\n",
    "    df2 = df2.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# 3. Stack them together\n",
    "# ignore_index=True resets the row numbers to 0, 1, 2, 3... all the way to the end\n",
    "full_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# 4. Remove duplicates (Optional but recommended)\n",
    "# Just in case you accidentally grabbed \"Hanoi\" in both files\n",
    "full_df = full_df.drop_duplicates()\n",
    "\n",
    "# 5. Save the final result\n",
    "full_df.to_csv(\"vietnam_weather_complete.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Merged! Total rows: {len(full_df)}\")\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1565547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 45520\n",
      "Sample of rows with matches:\n",
      "        time  temperature_2m_max  temperature_2m_min  temperature_2m_mean  \\\n",
      "0 2009-01-01                17.3                13.4                 15.1   \n",
      "1 2009-01-02                17.6                12.2                 14.8   \n",
      "2 2009-01-03                18.3                10.8                 14.4   \n",
      "3 2009-01-04                20.6                12.4                 16.2   \n",
      "4 2009-01-05                22.6                14.1                 17.6   \n",
      "\n",
      "   precipitation_sum rain_sum wind_speed_10m_max   city official_name  \\\n",
      "0                0.0      0.0               11.2  Hanoi         Hanoi   \n",
      "1                0.0      0.0                9.7  Hanoi         Hanoi   \n",
      "2                0.0      0.0                8.1  Hanoi         Hanoi   \n",
      "3                0.0      0.0               10.5  Hanoi         Hanoi   \n",
      "4                0.1      0.1               11.1  Hanoi         Hanoi   \n",
      "\n",
      "   humidity_avg  cloud_cover_avg  pressure_avg  \n",
      "0          70.0             44.0        1025.0  \n",
      "1          65.0             28.0        1025.0  \n",
      "2          74.0             40.0        1022.0  \n",
      "3          81.0             46.0        1018.0  \n",
      "4          90.0             75.0        1017.0  \n",
      "✅ Saved to 'vietnam_weather_final.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Datasets\n",
    "df_om = pd.read_csv(\"vietnam_weather_complete.csv\")       # Your Master Data (Open-Meteo)\n",
    "df_kag = pd.read_csv(\"vietnam_weather_kaggle.csv\")     # The source for extra columns\n",
    "\n",
    "# 2. Standardize Dates (Crucial for matching)\n",
    "# Open-Meteo is usually YYYY-MM-DD. Kaggle is usually DD/MM/YYYY.\n",
    "df_om[\"time\"] = pd.to_datetime(df_om[\"time\"])\n",
    "df_kag[\"date\"] = pd.to_datetime(df_kag[\"date\"], dayfirst=True)\n",
    "\n",
    "# 3. Standardize City Names\n",
    "# We need them to be IDENTICAL. \"Hanoi\" != \"Ha Noi\" to a computer.\n",
    "# Let's clean the Kaggle names to match your Open-Meteo names.\n",
    "\n",
    "city_map = {\n",
    "    \"Ha Noi\": \"Hanoi\",            # If Kaggle says Ha Noi, change to Hanoi\n",
    "    \"Thua Thien Hue\": \"Hue\",      # If Kaggle uses full province name\n",
    "    \"TP. Ho Chi Minh\": \"Ho Chi Minh City\",\n",
    "    \"Buon Me Thuot\": \"Buon Ma Thuot\",\n",
    "    # Add other mismatches here if you see empty results later\n",
    "}\n",
    "\n",
    "df_kag[\"province\"] = df_kag[\"province\"].replace(city_map)\n",
    "\n",
    "# 4. Prepare the Kaggle Data for Merging\n",
    "# We ONLY want the new columns, plus the keys (city, date)\n",
    "cols_to_add = [\"province\", \"date\", \"humidi\", \"cloud\", \"pressure\"]\n",
    "df_kag_clean = df_kag[cols_to_add].copy()\n",
    "\n",
    "# Rename Kaggle columns to match Open-Meteo keys\n",
    "df_kag_clean = df_kag_clean.rename(columns={\n",
    "    \"province\": \"city\",\n",
    "    \"date\": \"time\",\n",
    "    \"humidi\": \"humidity_avg\",   \n",
    "    \"cloud\": \"cloud_cover_avg\",\n",
    "    \"pressure\": \"pressure_avg\"\n",
    "})\n",
    "\n",
    "# 5. Perform the Merge (Left Join)\n",
    "merged_df = pd.merge(df_om, df_kag_clean, on=[\"city\", \"time\"], how=\"left\")\n",
    "\n",
    "# 6. Check results\n",
    "print(f\"Total rows: {len(merged_df)}\") \n",
    "print(\"Sample of rows with matches:\")\n",
    "# Show rows where we actually found humidity data\n",
    "print(merged_df[merged_df['humidity_avg'].notnull()].head())\n",
    "\n",
    "# 7. Save\n",
    "merged_df.to_csv(\"vietnam_weather_final.csv\", index=False)\n",
    "print(\"✅ Saved to 'vietnam_weather_final.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aea16d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dropped all 'Ha Noi' rows. Remaining rows: 40968\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load your data\n",
    "df = pd.read_csv(\"vietnam_weather_final.csv\")\n",
    "\n",
    "# 2. Filter: Keep rows where city is NOT \"Ha Noi\"\n",
    "df = df[df['city'] != \"Ha Noi\"]\n",
    "\n",
    "# Optional: Reset the index so it flows 0, 1, 2, 3... nicely\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 3. Save\n",
    "df.to_csv(\"vietnam_weather_final.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Dropped all 'Ha Noi' rows. Remaining rows: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
